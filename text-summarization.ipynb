{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Text or Document Summarization"]},{"cell_type":"markdown","metadata":{},"source":["## Extraction Based"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:14.793717Z","iopub.status.busy":"2023-03-20T14:46:14.793305Z","iopub.status.idle":"2023-03-20T14:46:15.947331Z","shell.execute_reply":"2023-03-20T14:46:15.945337Z","shell.execute_reply.started":"2023-03-20T14:46:14.793682Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from collections import defaultdict\n","from nltk.stem import WordNetLemmatizer\n","from nltk.probability import FreqDist\n","import heapq"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:15.950007Z","iopub.status.busy":"2023-03-20T14:46:15.949647Z","iopub.status.idle":"2023-03-20T14:46:16.116064Z","shell.execute_reply":"2023-03-20T14:46:16.114859Z","shell.execute_reply.started":"2023-03-20T14:46:15.949975Z"},"trusted":true},"outputs":[],"source":["nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import wordnet\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.118590Z","iopub.status.busy":"2023-03-20T14:46:16.118078Z","iopub.status.idle":"2023-03-20T14:46:16.127561Z","shell.execute_reply":"2023-03-20T14:46:16.125735Z","shell.execute_reply.started":"2023-03-20T14:46:16.118479Z"},"trusted":true},"outputs":[],"source":["# text = '''\n","# Back in 2019, a non-profit research group called OpenAI created a software program that could generate paragraphs of coherent text and perform rudimentary reading comprehension and analysis without specific instruction.\n","\n","# OpenAI initially decided not to make its creation, called GPT-2, fully available to the public out of fear that people with malicious intent could use it to generate massive amounts disinformation and propaganda. In a press release announcing its decision, the group called the program \"too dangerous\".\n","\n","# Fast forward three years, and artificial intelligence capabilities have increased exponentially.\n","\n","# In contrast to that last limited distribution, the next offering, GPT-3, was made readily available in November. The Chatbot-GPT interface derived from that programming was the service that launched a thousand news articles and social media posts, as reporters and experts tested its capabilities - often with eye-popping results.\n","\n","# Chatbot-GPT scripted stand-up routines in the style of the late comedian George Carlin about the Silicon Valley Bank failure. It opined on Christian theology. It wrote poetry. It explained quantum theory physics to a child as though it were rapper Snoop Dogg. Other AI models, like Dall-E, generated visuals so compelling they have sparked controversy over their inclusion on art websites.\n","\n","# Machines, at least to the naked eye, have achieved creativity.\n","\n","# On Tuesday, OpenAI debuted the latest iteration of its program, GPT-4, which it says has robust limits on abusive uses. Early clients include Microsoft, Merrill Lynch and the government of Iceland. And at the South by Southwest Interactive conference in Austin, Texas, this week - a global gathering of tech policymakers, investors and executives - the hottest topic of conversation was the potential, and power, of artificial intelligence programs.\n","\n","# Arati Prabhakar, director of the White House's Office of Science and Technology Policy, says she is excited about the possibilities of AI, but she also had a warning.\n","\n","# \"What we are all seeing is the emergence of this extremely powerful technology. This is an inflection point,\" she told a conference panel audience. \"All of history shows that these kinds of powerful new technologies can and will be used for good and for ill.\"\n","\n","# Her co-panelist, Austin Carson, was a bit more blunt.\n","\n","# \"If in six months you are not completely freaked the (expletive) out, then I will buy you dinner,\" the founder of SeedAI, an artificial intelligence policy advisory group, told the audience.\n","\n","# '''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.131912Z","iopub.status.busy":"2023-03-20T14:46:16.131485Z","iopub.status.idle":"2023-03-20T14:46:16.148672Z","shell.execute_reply":"2023-03-20T14:46:16.146444Z","shell.execute_reply.started":"2023-03-20T14:46:16.131872Z"},"trusted":true},"outputs":[],"source":["text = '''\n","Alice was not a bit hurt, and she jumped up on to her feet in a moment:\n","she looked up, but it was all dark overhead; before her was another long\n","passage, and the White Rabbit was still in sight, hurrying down it.\n","There was not a moment to be lost: away went Alice like the wind, and\n","was just in time to hear it say, as it turned a corner, \"Oh my ears and\n","whiskers, how late it's getting!\" She was close behind it when she\n","turned the corner, but the Rabbit was no longer to be seen: she found\n","herself in a long, low hall, which was lit up by a row of lamps hanging\n","from the roof.\n","\n","There were doors all round the hall, but they were all locked; and when\n","Alice had been all the way down one side and up the other, trying every\n","door, she walked sadly down the middle, wondering how she was ever to\n","get out again.\n","\n","Suddenly she came upon a little three-legged table, all made of solid\n","glass; there was nothing on it but a tiny golden key, and Alice's first\n","idea was that this might belong to one of the doors of the hall; but,\n","alas! either the locks were too large, or the key was too small, but at\n","any rate it would not open any of them. However, on the second time\n","round, she came upon a low curtain she had not noticed before, and\n","behind it was a little door about fifteen inches high: she tried the\n","little golden key in the lock, and to her great delight it fitted!\n","Alice opened the door and found that it led into a small passage, not\n","much larger than a rat-hole: she knelt down and looked along the passage\n","into the loveliest garden you ever saw. How she longed to get out of\n","that dark hall, and wander about among those beds of bright flowers and\n","those cool fountains, but she could not even get her head through the\n","doorway; \"and even if my head would go through,\" thought poor Alice, \"it\n","would be of very little use without my shoulders. Oh, how I wish I could\n","shut up like a telescope! I think I could, if I only knew how to begin.\"\n","For, you see, so many out-of-the-way things had happened lately, that\n","Alice had begun to think that very few things indeed were really\n","impossible.\n","\n","There seemed to be no use in waiting by the little door, so she went\n","back to the table, half hoping she might find another key on it, or at\n","any rate a book of rules for shutting people up like telescopes: this\n","time she found a little bottle on it (\"which certainly was not here\n","before,\" said Alice,) and tied round the neck of the bottle was a paper\n","label, with the words \"DRINK ME\" beautifully printed on it in large\n","letters.\n","\n","It was all very well to say \"Drink me,\" but the wise little Alice was\n","not going to do _that_ in a hurry. \"No, I'll look first,\" she said, \"and\n","see whether it's marked '_poison_' or not;\" for she had read several\n","nice little stories about children who had got burnt, and eaten up by\n","wild beasts, and other unpleasant things, all because they _would_ not\n","remember the simple rules their friends had taught them: such as, that a\n","red-hot poker will burn you if you hold it too long; and that, if you\n","cut your finger _very_ deeply with a knife, it usually bleeds; and she\n","had never forgotten that, if you drink much from a bottle marked\n","\"poison,\" it is almost certain to disagree with you, sooner or later.\n","\n","However, this bottle was _not_ marked \"poison,\" so Alice ventured to\n","taste it, and finding it very nice (it had, in fact, a sort of mixed\n","flavour of cherry-tart, custard, pineapple, roast turkey, coffee, and\n","hot buttered toast,) she very soon finished it off.\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.150562Z","iopub.status.busy":"2023-03-20T14:46:16.150113Z","iopub.status.idle":"2023-03-20T14:46:16.183597Z","shell.execute_reply":"2023-03-20T14:46:16.180872Z","shell.execute_reply.started":"2023-03-20T14:46:16.150518Z"},"trusted":true},"outputs":[],"source":["sentences = sent_tokenize(text)\n","sentences[:2]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.185856Z","iopub.status.busy":"2023-03-20T14:46:16.185381Z","iopub.status.idle":"2023-03-20T14:46:16.199015Z","shell.execute_reply":"2023-03-20T14:46:16.197172Z","shell.execute_reply.started":"2023-03-20T14:46:16.185811Z"},"trusted":true},"outputs":[],"source":["word_freq = defaultdict(int)\n","for i in range(len(sentences)-1):\n","    words = word_tokenize(sentences[i])\n","    \n","    for word in words:\n","        if word not in stop_words:\n","            word_freq[word] += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.201683Z","iopub.status.busy":"2023-03-20T14:46:16.201055Z","iopub.status.idle":"2023-03-20T14:46:16.220285Z","shell.execute_reply":"2023-03-20T14:46:16.218418Z","shell.execute_reply.started":"2023-03-20T14:46:16.201627Z"},"trusted":true},"outputs":[],"source":["word_freq"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.222386Z","iopub.status.busy":"2023-03-20T14:46:16.221760Z","iopub.status.idle":"2023-03-20T14:46:16.236995Z","shell.execute_reply":"2023-03-20T14:46:16.235874Z","shell.execute_reply.started":"2023-03-20T14:46:16.222336Z"},"trusted":true},"outputs":[],"source":["# Calculate the score for each sentence\n","sentence_scores = defaultdict(int)\n","for sentence in sentences:\n","    words = word_tokenize(sentence)\n","    for word in words:\n","        if word in word_freq:\n","            sentence_scores[sentence] += word_freq[word]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.238662Z","iopub.status.busy":"2023-03-20T14:46:16.238326Z","iopub.status.idle":"2023-03-20T14:46:16.253867Z","shell.execute_reply":"2023-03-20T14:46:16.252445Z","shell.execute_reply.started":"2023-03-20T14:46:16.238628Z"},"trusted":true},"outputs":[],"source":["sentence_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.258219Z","iopub.status.busy":"2023-03-20T14:46:16.257602Z","iopub.status.idle":"2023-03-20T14:46:16.264816Z","shell.execute_reply":"2023-03-20T14:46:16.263413Z","shell.execute_reply.started":"2023-03-20T14:46:16.258188Z"},"trusted":true},"outputs":[],"source":["# Select the top N sentences based on their scores\n","N = 3\n","summary_sentences = sorted(\n","    sentence_scores, \n","    key=sentence_scores.get, \n","    reverse=True)[:N]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.266927Z","iopub.status.busy":"2023-03-20T14:46:16.266099Z","iopub.status.idle":"2023-03-20T14:46:16.282719Z","shell.execute_reply":"2023-03-20T14:46:16.281712Z","shell.execute_reply.started":"2023-03-20T14:46:16.266892Z"},"trusted":true},"outputs":[],"source":["# Print the summary\n","print(\"Summary:\")\n","for sentence in summary_sentences:\n","    print(sentence)"]},{"cell_type":"markdown","metadata":{},"source":["# Abstraction Based"]},{"cell_type":"markdown","metadata":{},"source":["In this code, we first load the NLTK library and the stop words and lemmatizer for English. We then define the text that we want to summarize and tokenize it into sentences and words using the sent_tokenize() and word_tokenize() functions. We remove stop words and lemmatize the remaining words using the WordNetLemmatizer.\n","\n","Next, we calculate the frequency distribution of the remaining words using FreqDist(). We use this to calculate the term frequency (TF) scores for each sentence, which we store in a dictionary called tf_scores.\n","\n","We then calculate the inverse document frequency (IDF) scores for each word based on its frequency across all sentences in the text. We use this to calculate the TF-IDF scores for each sentence, which we store in a dictionary called tfidf_scores.\n","\n","Finally, we select the top N sentences with the highest TF-IDF scores using the nlargest() function from the heapq module and join them together into a summary.\n","\n","Note that this is just a basic implementation and there are many ways to improve the accuracy and efficiency of the summarization algorithm, such as by using more advanced natural language processing techniques or incorporating user feedback."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:16.285000Z","iopub.status.busy":"2023-03-20T14:46:16.284405Z","iopub.status.idle":"2023-03-20T14:46:21.890442Z","shell.execute_reply":"2023-03-20T14:46:21.888420Z","shell.execute_reply.started":"2023-03-20T14:46:16.284946Z"},"trusted":true},"outputs":[],"source":["import spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:21.893284Z","iopub.status.busy":"2023-03-20T14:46:21.892486Z","iopub.status.idle":"2023-03-20T14:46:22.673562Z","shell.execute_reply":"2023-03-20T14:46:22.671189Z","shell.execute_reply.started":"2023-03-20T14:46:21.893249Z"},"trusted":true},"outputs":[],"source":["nlp = spacy.load('en_core_web_sm')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.675499Z","iopub.status.busy":"2023-03-20T14:46:22.675165Z","iopub.status.idle":"2023-03-20T14:46:22.831718Z","shell.execute_reply":"2023-03-20T14:46:22.830447Z","shell.execute_reply.started":"2023-03-20T14:46:22.675470Z"},"trusted":true},"outputs":[],"source":["doc = nlp(text)\n","print(doc)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.833665Z","iopub.status.busy":"2023-03-20T14:46:22.833378Z","iopub.status.idle":"2023-03-20T14:46:22.838676Z","shell.execute_reply":"2023-03-20T14:46:22.837702Z","shell.execute_reply.started":"2023-03-20T14:46:22.833639Z"},"trusted":true},"outputs":[],"source":["sentence_lengths = [len(sent) for sent in doc.sents]\n","print(sentence_lengths)"]},{"cell_type":"markdown","metadata":{},"source":["the line `sentence_lengths = [len(sent) for sent in doc.sents]`, we are calculating the length of each sentence in the document.\n","\n","Here's how it works:\n","\n","doc.sents is a generator that yields each sentence in the document as a Span object.\n","We use a list comprehension to iterate over each sentence in doc.sents and apply the len() function to it to get its length.\n","The resulting list contains the length of each sentence in the document in the order that they were yielded by doc.sents.\n","So, sentence_lengths is a list of integers representing the length (in characters) of each sentence in the document. We can use this information to filter out sentences that are too short or too long to be included in the summary, which we do later in the code."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.840208Z","iopub.status.busy":"2023-03-20T14:46:22.839913Z","iopub.status.idle":"2023-03-20T14:46:22.849606Z","shell.execute_reply":"2023-03-20T14:46:22.848431Z","shell.execute_reply.started":"2023-03-20T14:46:22.840166Z"},"trusted":true},"outputs":[],"source":["# Calculate the median sentence length\n","median_sentence_length = sorted(sentence_lengths)[len(sentence_lengths) // 2]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.851396Z","iopub.status.busy":"2023-03-20T14:46:22.850920Z","iopub.status.idle":"2023-03-20T14:46:22.864679Z","shell.execute_reply":"2023-03-20T14:46:22.862235Z","shell.execute_reply.started":"2023-03-20T14:46:22.851367Z"},"trusted":true},"outputs":[],"source":["print(median_sentence_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.866303Z","iopub.status.busy":"2023-03-20T14:46:22.865964Z","iopub.status.idle":"2023-03-20T14:46:22.875644Z","shell.execute_reply":"2023-03-20T14:46:22.874178Z","shell.execute_reply.started":"2023-03-20T14:46:22.866272Z"},"trusted":true},"outputs":[],"source":["candidate_sentences = []\n","# Loop over each sentence in doc.sents\n","for sent in doc.sents:\n","    # Calculate the length of the sentence\n","    sent_length = len(sent)\n","    # Calculate the lower and upper bounds for acceptable sentence lengths\n","    lower_bound = median_sentence_length / 2\n","    upper_bound = median_sentence_length * 2\n","    # Check if the sentence length is within the acceptable range\n","    if sent_length > lower_bound and sent_length < upper_bound:\n","        # If the sentence length is within the acceptable range, add it to the list of candidate sentences\n","        candidate_sentences.append(sent)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.879036Z","iopub.status.busy":"2023-03-20T14:46:22.878546Z","iopub.status.idle":"2023-03-20T14:46:22.891952Z","shell.execute_reply":"2023-03-20T14:46:22.890761Z","shell.execute_reply.started":"2023-03-20T14:46:22.878994Z"},"trusted":true},"outputs":[],"source":["candidate_sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.893749Z","iopub.status.busy":"2023-03-20T14:46:22.893281Z","iopub.status.idle":"2023-03-20T14:46:22.902422Z","shell.execute_reply":"2023-03-20T14:46:22.900477Z","shell.execute_reply.started":"2023-03-20T14:46:22.893649Z"},"trusted":true},"outputs":[],"source":["# filter our sentences that are too short or too long\n","# candidate_sentences = [sent for sent in doc.sents if len(sent) > median_sentence_length / 2 and len(sent) < median_sentence_length * 2]\n","# candidate_sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.904340Z","iopub.status.busy":"2023-03-20T14:46:22.903859Z","iopub.status.idle":"2023-03-20T14:46:22.917957Z","shell.execute_reply":"2023-03-20T14:46:22.916853Z","shell.execute_reply.started":"2023-03-20T14:46:22.904309Z"},"trusted":true},"outputs":[],"source":["similarity_matrix = []\n","for i in range(len(candidate_sentences)):\n","    row = []\n","    for j in range(len(candidate_sentences)):\n","        if i == j:\n","            row.append(0)\n","        else:\n","            row.append(candidate_sentences[i].similarity(candidate_sentences[j]))\n","    similarity_matrix.append(row)\n","\n","    \n","print(similarity_matrix)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.922426Z","iopub.status.busy":"2023-03-20T14:46:22.920941Z","iopub.status.idle":"2023-03-20T14:46:22.929375Z","shell.execute_reply":"2023-03-20T14:46:22.928020Z","shell.execute_reply.started":"2023-03-20T14:46:22.922382Z"},"trusted":true},"outputs":[],"source":["# Rank the sentences based on their centrality in the similarity graph\n","centrality_scores = [sum(row) for row in similarity_matrix]\n","# sentence_indices = sorted(range(len(candidate_sentences)), key=lambda i: centrality_scores[i], reverse=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.931289Z","iopub.status.busy":"2023-03-20T14:46:22.930929Z","iopub.status.idle":"2023-03-20T14:46:22.941825Z","shell.execute_reply":"2023-03-20T14:46:22.940115Z","shell.execute_reply.started":"2023-03-20T14:46:22.931255Z"},"trusted":true},"outputs":[],"source":["sentence_indices = sorted(\n","    range(len(candidate_sentences)), \n","    key=lambda i: centrality_scores[i], \n","    reverse=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.945081Z","iopub.status.busy":"2023-03-20T14:46:22.943688Z","iopub.status.idle":"2023-03-20T14:46:22.962362Z","shell.execute_reply":"2023-03-20T14:46:22.960733Z","shell.execute_reply.started":"2023-03-20T14:46:22.945037Z"},"trusted":true},"outputs":[],"source":["centrality_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.964277Z","iopub.status.busy":"2023-03-20T14:46:22.963904Z","iopub.status.idle":"2023-03-20T14:46:22.977927Z","shell.execute_reply":"2023-03-20T14:46:22.976050Z","shell.execute_reply.started":"2023-03-20T14:46:22.964241Z"},"trusted":true},"outputs":[],"source":["sentence_indices"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:46:22.979809Z","iopub.status.busy":"2023-03-20T14:46:22.979441Z","iopub.status.idle":"2023-03-20T14:46:22.987777Z","shell.execute_reply":"2023-03-20T14:46:22.986891Z","shell.execute_reply.started":"2023-03-20T14:46:22.979749Z"},"trusted":true},"outputs":[],"source":["# Select the top N sentences with the highest centrality scores\n","N =2\n","summary_sentences = [candidate_sentences[i] for i in sentence_indices[:N]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:58:17.519956Z","iopub.status.busy":"2023-03-20T14:58:17.519488Z","iopub.status.idle":"2023-03-20T14:58:17.529539Z","shell.execute_reply":"2023-03-20T14:58:17.527209Z","shell.execute_reply.started":"2023-03-20T14:58:17.519916Z"},"trusted":true},"outputs":[],"source":["summary_sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T14:58:31.546673Z","iopub.status.busy":"2023-03-20T14:58:31.546311Z","iopub.status.idle":"2023-03-20T14:58:31.553260Z","shell.execute_reply":"2023-03-20T14:58:31.551882Z","shell.execute_reply.started":"2023-03-20T14:58:31.546641Z"},"trusted":true},"outputs":[],"source":["# Print summary\n","summary = ' '.join([sent.text for sent in summary_sentences])\n","print(summary)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
